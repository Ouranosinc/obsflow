#TODO: env
# Workflow to extract and analyse observation data


# This workflow is made to know exactly where to restart if the code is stopped.
# It looks if the result of a task exists in the project catalog before executing the task.
# The workflow does NOT automatically remove intermediate files. You might run out of space.

# List of task to accomplish in the workflow
# Each task will iterate over all simulations before moving on to the next task.
# It might be useful to start by running it once over all tasks on a single simulation
#  (by modifying extract:simulation:search_data_catalogs:other_search_criteria:)
# to make sure all tasks work properly before launching it for all simulations.
tasks:
   - extract # Extract station data, (gridded observation data), and reanalysis data.
   - indicators # Compute xclim indicators on the datasets.
   - climatologies # Compute climatological operations for the indicators (mean, std, trend).
   - performance # Compute performance metrics of type xsdba.measures.StatisticalPropertyMeasure between observations and reconstructions
   - regional_mean
   - coherence

# Task Arguments

extract:  # ------------------------------------- Extraction --------------------------------------------
#reanalysis
  reconstruction:
    dask:
      n_workers: 2
      threads_per_worker: 3
      memory_limit:
        15GB
    search_data_catalogs:
      allow_resampling: False
      allow_conversion: True
      variables_and_freqs: # &var_and_freq # this is an anchor. more on anchors:  https://support.atlassian.com/bitbucket-cloud/docs/yaml-anchors/
        tasmax: D
        tasmin: D
        pr: D
        tas: D
      other_search_criteria:
        source:
          - ERA5-Land
          - RDRS
          - CaSR
          - EMDNA
          - PCICBlend
    extract_dataset: &extract
      region: 
        name: Quebec
        method: shape
        #buffer: 0.03
      periods: 
        - 1980
        - 2025
    save:
      encoding:
        tas: &f32
          dtype: float32
        tasmax: *f32
        tasmin: *f32
        pr: *f32
      rechunk:
        time: -1
        X: 30
        Y: 30

# station observations AHCCD
  station-tas:  # ------------------------------------- Station Temperature -------------------------------------
    dask:
      n_workers: 1
      threads_per_worker: 2
      memory_limit:
        12GB
    search_data_catalogs:
      allow_resampling: False
      allow_conversion: True
      variables_and_freqs:
        tasmax: D
        tasmin: D
        tas: D
      other_search_criteria:
        source: AHCCD
    extract_dataset: *extract
    xarray_open_kwargs:
      chunks:
        station: 1
    save:
      mode: o
      rechunk:
        time: -1
        station: 50

  station-pr:  # ------------------------------------- Station Precipitation -------------------------------------
    dask:
      n_workers: 1
      threads_per_worker: 2
      memory_limit:
        12GB
    search_data_catalogs:
      allow_resampling: False
      allow_conversion: True
      variables_and_freqs:
        pr: D
      other_search_criteria:
        source: AHCCD
    extract_dataset: *extract
    save:
      rechunk:
       time: -1
       station: 50



indicators:  # ------------------------------------- Indicators --------------------------------------------------
  dask:
    n_workers: 8
    threads_per_worker: 5
    memory_limit: "8GB"
  inputs:
    processing_level: extracted
  ref_percentiles: #TODO: check this
    from: 1981-01-01
    to: 2010-12-31
  save:
    rechunk:
      time: -1

aggregate:  # ------------------------------------- Climatological Operations -------------------------------------
  dask:
    n_workers: 16
    threads_per_worker: 4
    memory_limit: "15GB"
  periods:
    - ['1981', '2010']
    - ['1991', '2020']
  input:
    processing_level: indicators
  climatological_mean: 
    op: mean
    min_periods: &min_periods_val 25
  vars_for_interannual_std: &indicators #TODO: make naming clearer
    - tg_mean_annual
    - tg_mean_seasonal
    - pr_mean_annual
    - pr_mean_seasonal
  # vars_for_climatological_std:
  #   - pr_std
  climatological_std: # automatically passed to the function
    op: std
    min_periods: *min_periods_val

performance:  # ------------------------------------- Performance --------------------------------------------------
  # Defines which statistical metrics to compute using functions from xsdba.measures.
  dask:
    n_workers: 8
    threads_per_worker: 5
    memory_limit: "8GB"
  input:
    observation: # Parameters used to search exclusively for observation data in the catalog.
      type: ['station-pr', 'station-tas']
    reconstruction: # Parameters used to search exclusively for reconstruction data in the catalog.
      type: ['reconstruction']
  period: [1981, 2010]
  minimum_years: 20
  # Expected "statistics" YAML dictionary structure:
  #
  #   statistics:
  #      STATISTIC:
  #         - variable: VARIABLE1
  #         - variable: VARIABLE2
  #         - ...
  #
  # STATISTIC: Which statistic we're computing            e.g., 'rmse', 'mae', etc.
  # VARIABLE: Which variables we're computing it for      e.g., 'tg_mean_annual', 'pr_mean_seasonal'

  statistics:
    rmse:
      - variable: tg_mean_annual
      - variable: tg_mean_seasonal
      - variable: pr_mean_annual
      - variable: pr_mean_seasonal

  save:
    rechunk:
      station: -1


regional_mean: # ------------------------------------- Regional mean --------------------------------------------------
  dask:
    n_workers: 4
    threads_per_worker: 2
    memory_limit: "8GB"
  search_params:
    - variable: tg_mean_annual_rmse
    - variable: tg_mean_seasonal_rmse
    - variable: pr_mean_annual_rmse
    - variable: pr_mean_seasonal_rmse
  #spatial_dims: ["lat", "lon", "rlat", "rlon"] # The dimensions which get averaged out
  save:
    rechunk:
      time: -1

coherence:  # ------------------------------------- Coherence --------------------------------------------------
  dask:
    n_workers: 4
    threads_per_worker: 4
    memory_limit: "8GB"
  search_params:
    - variable: "tg_mean_annual_clim_mean"
      type: &type reconstruction
    - variable: "pr_mean_annual_clim_mean"
      type: *type
    - variable: "tg_mean_seasonal_clim_mean"
      type: *type
    - variable: "pr_mean_seasonal_clim_mean"
      type: *type



# General Arguments

project: # argument to create the project
  name: ObsFlow - A workflow for observation data - Stage 2025
  version: 0.3
  description: A xscen workflow for extracting observation data and performing climatic analysis
  id: obsflow

scripting: # send an email when code fails or succeed
  subject: ObsFlow - A workflow for observation data
  send_mail_on_exit:
    msg_err: I crashed, something went wrong!
    on_error_only: True

set_options:
  data_validation: log
  check_missing: wmo

io: 
  save_to_zarr: # passed automatically to all save_to_zarr
    mode: o 

dask: # general dask arguments
  array.slicing.split_large_chunks: False

logging: # general logging args
  formatters:
    default:
      format: '%(asctime)s %(levelname)-8s %(name)-15s %(message)s'
      datefmt: '%Y-%m-%d %H:%M:%S'
  handlers:
    console:
      class : logging.StreamHandler
      formatter: default
      level : INFO
  loggers:
    xscen:
      propagate: False
      level: INFO
      handlers: [console]

to_dataset_dict: # parameters to open datasets
  xarray_open_kwargs:
    decode_timedelta: False
